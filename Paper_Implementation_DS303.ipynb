{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtTNs1lVXP/eniv/5btAb9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PrakritiShetty/DS303_Project_Paper_Implementation/blob/main/Paper_Implementation_DS303.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Downloading and Preprocessing"
      ],
      "metadata": {
        "id": "htXt9HcO3B1M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3JWPsdNPdZ1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import albumentations as A\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "IMAGE_FORMAT = \".png\"\n",
        "# generating LR images from HR by bicubic downsampling. Average is simple avg, bicubic is weighted avg and subsampling is subsitution.\n",
        "DOWNSAMPLE_MODE = Image.BICUBIC\n",
        "COLOR_CHANNELS = 3\n",
        "\n",
        "HR_IMG_SIZE = (648, 648) \n",
        "UPSCALING_FACTOR = 4\n",
        "LR_IMG_SIZE = (HR_IMG_SIZE[0] // UPSCALING_FACTOR, HR_IMG_SIZE[1] // UPSCALING_FACTOR) # used // for integer division"
      ],
      "metadata": {
        "id": "mkGwuHNC0CrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DIV2K_Dataset(keras.utils.Sequence):\n",
        "   \n",
        "   # keras.utils.sequence is a data generator - used in situations like when we need advanced control over sample generation or when simple data does not fit into memory and must be loaded dynamically\n",
        "    \n",
        "    def __init__(self, hr_image_folder: str, batch_size: int, set_type: str):\n",
        "        self.batch_size = batch_size\n",
        "        self.hr_image_folder = hr_image_folder\n",
        "        self.images = np.sort([\n",
        "            x for x in os.listdir(hr_image_folder) if x.endswith(IMAGE_FORMAT)\n",
        "        ])\n",
        "\n",
        "        if set_type == \"train\":\n",
        "          self.images = self.images[:-200] # 700 images for training\n",
        "        elif set_type == \"val\":\n",
        "          self.images = self.images[-200:-100] # 100 images for validation\n",
        "        else:\n",
        "          self.images = self.images[-100:] # 100 images for testing\n",
        "\n",
        "        # data augmentation\n",
        "        # done on HR images only, then LR will be made from that.\n",
        "        # for training and validation sets, data augmentation includes scaling and rotation\n",
        "        if set_type in [\"train\", \"val\"]:\n",
        "            self.transform = A.Compose(\n",
        "                [\n",
        "                    A.RandomCrop(width=HR_IMG_SIZE[0], height=HR_IMG_SIZE[1], p=1.0),\n",
        "                    A.RandomRotate90(),\n",
        "                    # A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.90,rotate_limit=45, p=.75),\n",
        "                    A.OneOf([A.augmentations.geometric.resize.RandomScale (scale_limit=0.6, interpolation=1, always_apply=False, p=0.5)],[A.augmentations.geometric.resize.RandomScale (scale_limit=0.7, interpolation=1, always_apply=False, p=0.5)][A.augmentations.geometric.resize.RandomScale (scale_limit=0.8, interpolation=1, always_apply=False, p=0.5)][A.augmentations.geometric.resize.RandomScale (scale_limit=0.9, interpolation=1, always_apply=False, p=0.5)]),\n",
        "                    A.OneOf([A.HorizontalFlip(p=0.5), A.VerticalFlip(p=0.5)])\n",
        "                    \n",
        "                ]\n",
        "            )\n",
        "        else: \n",
        "            self.transform = A.Compose(\n",
        "                [\n",
        "                    A.RandomCrop(width=HR_IMG_SIZE[0], height=HR_IMG_SIZE[1], p=1.0),\n",
        "                ]\n",
        "            )\n",
        "\n",
        "        self.to_float = A.ToFloat(max_value=255)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images) // self.batch_size\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        random.shuffle(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # batch of samples\n",
        "        i = idx * self.batch_size\n",
        "        batch_images = self.images[i : i + self.batch_size]\n",
        "        batch_hr_images = np.zeros((self.batch_size,) + HR_IMG_SIZE + (COLOR_CHANNELS,))\n",
        "        batch_lr_images = np.zeros((self.batch_size,) + LR_IMG_SIZE + (COLOR_CHANNELS,))\n",
        "\n",
        "\n",
        "        for i, image in enumerate(batch_images):\n",
        "           \n",
        "            hr_image = np.array(Image.open(os.path.join(self.hr_image_folder, image)))  \n",
        "\n",
        "                 \n",
        "            hr_image_transform = self.transform(image=hr_image)[\"image\"]\n",
        "            hr_image_transform_1 = Image.fromarray(hr_image_transform)\n",
        "            lr_image_transform = hr_image_transform_1.resize(\n",
        "                LR_IMG_SIZE, resample=DOWNSAMPLE_MODE\n",
        "            )\n",
        "            lr_image_transform_1 = Image.fromarray(lr_image_transform)\n",
        "\n",
        "            batch_hr_images[i] = self.to_float(image=hr_image_transform)[\"image\"]\n",
        "            batch_lr_images[i] = self.to_float(image=lr_image_transform)[\"image\"]\n",
        "\n",
        "        return (batch_lr_images, batch_hr_images)\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "qsch9s0x0DO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Building"
      ],
      "metadata": {
        "id": "qLY7f4nw1RLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential, initializers\n",
        "from keras.layers import Conv2D, Conv2DTranspose, InputLayer, PReLU, Activation\n",
        "\n",
        "# from utils.constants import LR_IMG_SIZE, UPSCALING_FACTOR, COLOR_CHANNELS"
      ],
      "metadata": {
        "id": "P9L1pPQUz0qG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model( d: int, s: int, m: int, input_size: tuple = LR_IMG_SIZE, upscaling_factor: int = UPSCALING_FACTOR, color_channels: int = COLOR_CHANNELS):\n",
        "    model = Sequential()\n",
        "    model.add( InputLayer( input_shape=(input_size[0], input_size[1], color_channels)))\n",
        "\n",
        "    # feature extraction\n",
        "    model.add(\n",
        "        Conv2D(\n",
        "            kernel_size = 5,\n",
        "            filters = d,\n",
        "            padding=\"valid\",\n",
        "            kernel_initializer=initializers.HeNormal(),\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # activation func after every conv layer\n",
        "    model.add( PReLU( alpha_initializer=\"zeros\", shared_axes=[1, 2]))\n",
        "\n",
        "    # shrinking\n",
        "    model.add(\n",
        "        Conv2D(\n",
        "            kernel_size = 1,\n",
        "            filters = s,\n",
        "            padding=\"valid\",\n",
        "            kernel_initializer=initializers.HeNormal(),\n",
        "        )\n",
        "    )\n",
        "\n",
        "    model.add( PReLU( alpha_initializer=\"zeros\", shared_axes=[1, 2]))\n",
        "\n",
        "    # non linear mapping\n",
        "    for _ in range(m):\n",
        "        model.add(\n",
        "            Conv2D(\n",
        "                kernel_size = 3,\n",
        "                filters = s,\n",
        "                padding=\"valid\",\n",
        "                kernel_initializer=initializers.HeNormal(),\n",
        "            )\n",
        "        )\n",
        "    \n",
        "    model.add(PReLU(alpha_initializer=\"zeros\", shared_axes=[1, 2]))\n",
        "\n",
        "    # expanding\n",
        "    model.add(\n",
        "        Conv2D(\n",
        "            kernel_size=1, \n",
        "            filters=d, \n",
        "            padding=\"valid\"\n",
        "          )\n",
        "      )\n",
        "    \n",
        "    model.add(PReLU(alpha_initializer=\"zeros\", shared_axes=[1, 2]))\n",
        "\n",
        "    # deconvolution\n",
        "    model.add(\n",
        "        Conv2DTranspose(\n",
        "            kernel_size=9,\n",
        "            filters=color_channels,\n",
        "            strides=upscaling_factor,\n",
        "            padding=\"valid\",\n",
        "            kernel_initializer=initializers.RandomNormal(mean=0, stddev=0.001),\n",
        "        )\n",
        "    )\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "0zqvf20b9HC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RC1SfORfStTl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}